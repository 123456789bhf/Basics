{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7855278b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvae_anomaly_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mVAE\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VAEAnomalyTabular\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvae_anomaly_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rand_dataset\n\u001b[1;32m---> 15\u001b[0m EXPERIMENT_FOLDER \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;18;43m__file__\u001b[39;49m)\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_folder_run\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Path:\n\u001b[0;32m     19\u001b[0m     run_path: Path \u001b[38;5;241m=\u001b[39m EXPERIMENT_FOLDER \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "from ignite.engine import Engine, Events\n",
    "from ignite.metrics import Average, RunningAverage\n",
    "from path import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from ignite.contrib.handlers.tqdm_logger import ProgressBar\n",
    "\n",
    "from vae_anomaly_detection.VAE import VAEAnomalyTabular\n",
    "from vae_anomaly_detection.dataset import rand_dataset\n",
    "\n",
    "EXPERIMENT_FOLDER = Path(__file__).parent.parent\n",
    "\n",
    "\n",
    "def get_folder_run() -> Path:\n",
    "    run_path: Path = EXPERIMENT_FOLDER / 'run'\n",
    "    if not run_path.exists(): run_path.mkdir()\n",
    "    i = 0\n",
    "    while (run_path / str(i)).exists():\n",
    "        i += 1\n",
    "    folder_run = run_path / str(i)\n",
    "    folder_run.mkdir()\n",
    "    return folder_run\n",
    "\n",
    "\n",
    "class TrainStep:\n",
    "\n",
    "    def __init__(self, model, opt, device=None):\n",
    "        self.model = model\n",
    "        self.opt = opt\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, engine, batch):\n",
    "        x = batch[0]\n",
    "        if self.device: \n",
    "            x = x.to(self.device)\n",
    "        pred_output = self.model(x)\n",
    "        pred_output['loss'].backward()  # loss function is computed inside the VAE class since it is unsupervised\n",
    "        self.opt.step()\n",
    "        return pred_output\n",
    "\n",
    "\n",
    "def train(model, opt, dloader, epochs: int, experiment_folder, device, progress_bar=True, steps_log_loss=1_000, steps_log_norm_params=10_000):\n",
    "    step = TrainStep(model, opt, device)\n",
    "    trainer = Engine(step)\n",
    "\n",
    "    Average(lambda o: o['loss']).attach(trainer, 'avg_loss')\n",
    "    RunningAverage(output_transform=lambda o: o['loss']).attach(trainer, 'running_avg_loss')\n",
    "\n",
    "    if progress_bar:\n",
    "        ProgressBar().attach(trainer, ['running_avg_loss'])\n",
    "\n",
    "    setup_logger(experiment_folder, trainer, model, \n",
    "                 steps_log_loss, steps_log_norm_params)\n",
    "\n",
    "    trainer.add_event_handler(Events.EPOCH_COMPLETED,\n",
    "                              lambda e: torch.save(model.state_dict(), experiment_folder / 'model.pth'))\n",
    "\n",
    "    trainer.run(dloader, epochs)\n",
    "\n",
    "\n",
    "def setup_logger(experiment_folder, trainer, model, freq_loss: int = 1_000, freq_norm_params: int = 1_000):\n",
    "    logger = SummaryWriter(log_dir=experiment_folder)\n",
    "    for l in ['loss', 'kl', 'recon_loss']:\n",
    "        event_handler = lambda e, l=l: logger.add_scalar(f'train/{l}', e.state.output[l], e.state.iteration)\n",
    "        trainer.add_event_handler(Events.ITERATION_COMPLETED(every=freq_loss), event_handler)\n",
    "\n",
    "    def log_norm(engine, logger, model=model):\n",
    "        norm1 = sum(p.norm(1) for p in model.parameters())\n",
    "        norm1_grad = sum(p.grad.norm(1) for p in model.parameters() if p.grad is not None)\n",
    "        it = engine.state.iteration\n",
    "        logger.add_scalar('train/norm1_params', norm1, it)\n",
    "        logger.add_scalar('train/norm1_grad', norm1_grad, it)\n",
    "\n",
    "    trainer.add_event_handler(Events.ITERATION_COMPLETED(every=freq_norm_params), log_norm, logger=logger)\n",
    "\n",
    "\n",
    "def get_args() -> argparse.Namespace:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--input-size', '-i', type=int, required=True, dest='input_size')\n",
    "    parser.add_argument('--latent-size', '-l', type=int, required=True, dest='latent_size')\n",
    "    parser.add_argument('--num-resamples', '-L', type=int, dest='num_resamples', default=10,\n",
    "                        help='Number of resamples in the latent distribution during training')\n",
    "    parser.add_argument('--epochs', '-e', type=int, dest='epochs', default=100)\n",
    "    parser.add_argument('--batch-size', '-b', type=int, dest='batch_size', default=32)\n",
    "    parser.add_argument('--device', '-d', type=str, dest='device', default='cuda:0')\n",
    "    parser.add_argument('--lr', type=float, dest='lr', default=1e-4)\n",
    "    parser.add_argument('--no-progress-bar', action='store_true', dest='no_progress_bar')\n",
    "    parser.add_argument('--steps-log-loss', type=int, dest='steps_log_loss', default=1_000)\n",
    "    parser.add_argument('--steps-log-norm-params', type=int, \n",
    "                        dest='steps_log_norm_params', default=1_000)\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def store_codebase_into_experiment(experiment_folder):\n",
    "    with open(Path(__file__).parent / 'VAE.py') as f:\n",
    "        code = f.read()\n",
    "    with open(experiment_folder / 'vae.py', 'w') as f:\n",
    "        f.write(code)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = get_args()\n",
    "    print(args)\n",
    "    experiment_folder = get_folder_run()\n",
    "    model = VAEAnomalyTabular(args.input_size, args.latent_size, args.num_resamples).to(args.device)\n",
    "    opt = torch.optim.Adam(model.parameters(), args.lr)\n",
    "    dloader = DataLoader(rand_dataset(), args.batch_size)\n",
    "\n",
    "    store_codebase_into_experiment(experiment_folder)\n",
    "    with open(experiment_folder / 'config.yaml', 'w') as f:\n",
    "        yaml.dump(args, f)\n",
    "\n",
    "    train(model, opt, dloader, args.epochs, experiment_folder, args.device, not args.no_progress_bar,\n",
    "          args.steps_log_loss, args.steps_log_norm_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a107b41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
