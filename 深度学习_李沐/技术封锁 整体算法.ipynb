{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b25fe6ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'baostock'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 该模型为技术封锁场景下的主要模型之一，模型共包含五部分：数据获取、数据预处理、模型搭建、模型训练、指标检测。\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# 其中：\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 预处理部分包括两类算法：MinMax数据归一化、数据随机打散；\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 模型搭建包括一类算法： 自编码器算法；\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 模型训练部分包括两类算法： 随机梯度下降算法类（Adma、SGD等）、反向传播算法；\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 另外为了使模型稳健的运行，增加了两类模型优化算法： 参数随机初始化算法、正则化算法。\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbaostock\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mbs\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'baostock'"
     ]
    }
   ],
   "source": [
    "# 该模型为技术封锁场景下的主要模型之一，模型共包含五部分：数据获取、数据预处理、模型搭建、模型训练、指标检测。\n",
    "# 其中：\n",
    "# 预处理部分包括两类算法：MinMax数据归一化、数据随机打散；\n",
    "# 模型搭建包括一类算法： 自编码器算法；\n",
    "# 模型训练部分包括两类算法： 随机梯度下降算法类（Adma、SGD等）、反向传播算法；\n",
    "# 另外为了使模型稳健的运行，增加了两类模型优化算法： 参数随机初始化算法、正则化算法。\n",
    "\n",
    "\n",
    "import baostock as bs\n",
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### 一、数据获取 ###\n",
    "# 登陆系统\n",
    "lg = bs.login()\n",
    "print('login respond error_code:'+lg.error_code)\n",
    "print('login respond  error_msg:'+lg.error_msg)\n",
    "\n",
    "# 获取沪深A股历史K线数据\n",
    "# 分钟线指标：date,time,code,open,high,low,close,volume,amount,adjustflag\n",
    "rs = bs.query_history_k_data_plus(\"sh.603259\",\n",
    "    \"date,time,code,open,high,low,close,volume,amount,adjustflag\",\n",
    "    start_date='2021-05-01', end_date='2021-12-31',\n",
    "    frequency=\"5\", adjustflag=\"3\")\n",
    "print('query_history_k_data_plus respond error_code:'+rs.error_code)\n",
    "print('query_history_k_data_plus respond  error_msg:'+rs.error_msg)\n",
    "\n",
    "# 打印获取的数据集\n",
    "data_list = []\n",
    "while (rs.error_code == '0') & rs.next():\n",
    "    # 获取一条记录，将记录合并在一起\n",
    "    data_list.append(rs.get_row_data())\n",
    "result = pd.DataFrame(data_list, columns=rs.fields)\n",
    "\n",
    "# 数据集输出到csv文件 \n",
    "result.to_csv(\"D:\\\\ymkd.csv\", index=False)\n",
    "print(result)\n",
    "\n",
    "# 登出系统\n",
    "bs.logout()\n",
    "\n",
    "# 读取数据\n",
    "merged_data = pd.read_csv('D:\\\\ymkd.csv', index_col='time',\n",
    "                              usecols=['time','open','high','low','close','volume','amount','adjustflag'])\n",
    "merged_data.index = pd.to_datetime(merged_data.index, format='%Y%m%d%H%M%S%f')\n",
    "\n",
    "####乖离率计算函数\n",
    "def bias(df,N):\n",
    "    label='bias_{}'.format(N)\n",
    "    df[label]=(df['close']-df['close'].rolling(N,min_periods=1).mean())/df['close'].rolling(N,min_periods=1).mean()*100\n",
    "    df[label]=df[label].map(lambda x:round(x,2))\n",
    "    return df.iloc[-1][label]\n",
    "bias(merged_data,6)\n",
    "print(merged_data.head())\n",
    "# merged_data.plot()\n",
    "\n",
    "# 设定训练集和测试集的时间区间\n",
    "dataset_train = merged_data['20210506093500':'20210630150000']\n",
    "dataset_test = merged_data['20210630150000':]\n",
    "dataset_train.plot(figsize=(12, 6))\n",
    "\n",
    "\n",
    "\n",
    "### 二、数据预处理 ###\n",
    "# 算法1：MinMax数据归一化\n",
    "scaler = preprocessing.MinMaxScaler()  \n",
    "X_train = pd.DataFrame(scaler.fit_transform(dataset_train),columns=dataset_train.columns,index=dataset_train.index)\n",
    "\n",
    "# 算法2：数据随机打散\n",
    "X_train.sample(frac=1)\n",
    "\n",
    "X_test = pd.DataFrame(scaler.transform(dataset_test),columns=dataset_test.columns,index=dataset_test.index)\n",
    "\n",
    "\n",
    "\n",
    "### 三、模型搭建：建立自编码器模型 ###\n",
    "# 算法3：自编码器算法\n",
    "def AutoEncoder_build(model, X_train, act_func):\n",
    "    tf.random.set_seed(10)\n",
    "\n",
    "    # act_func = 'elu'\n",
    "\n",
    "    # Input layer:\n",
    "    model = tf.keras.Sequential()  # Sequential() is a container that describes the network structure of the neural network, sequentially processing the model\n",
    "\n",
    "    # First hidden layer, connected to input vector X.\n",
    "    model.add(tf.keras.layers.Dense(10, activation=act_func,  # activation function\n",
    "                                    kernel_initializer='glorot_uniform',  # Weight initialization  算法4：参数随机初始化算法\n",
    "                                    kernel_regularizer=tf.keras.regularizers.l2(0.0),   # 算法5：正则化算法\n",
    "                                    # Regularization to prevent overfitting\n",
    "                                    input_shape=(X_train.shape[1],)\n",
    "                                    )\n",
    "              )\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(2, activation=act_func,\n",
    "                                    kernel_initializer='glorot_uniform'))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(10, activation=act_func,\n",
    "                                    kernel_initializer='glorot_uniform'))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(X_train.shape[1],\n",
    "                                    kernel_initializer='glorot_uniform'))\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam')  # 设置编译器\n",
    "\n",
    "    print(model.summary())\n",
    "    tf.keras.utils.plot_model(model, show_shapes=True)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model = AutoEncoder_build(model=model, X_train=X_train, act_func='elu')\n",
    "\n",
    "\n",
    "\n",
    "### 四、模型训练 ###\n",
    "# 算法6：随机梯度下降算法类（Adma、SGD等）\n",
    "# 算法7：反向传播算法\n",
    "def AutoEncoder_main(model, Epochs, BATCH_SIZE, validation_split):\n",
    "    # Train model for 100 epochs, batch size of 10:\n",
    "    # noise\n",
    "    factor = 0.5\n",
    "    X_train_noise = X_train + factor * np.random.normal(0, 1, X_train.shape)\n",
    "    X_train_noise = np.clip(X_train_noise, 0., 1.)\n",
    "\n",
    "    history = model.fit(np.array(X_train_noise), np.array(X_train),\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        epochs=Epochs,\n",
    "                        shuffle=True, \n",
    "                        validation_split=validation_split,  # Training set ratio\n",
    "                        #                       validation_data=(X_train,X_train), # Validation set\n",
    "                        verbose=1)\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "# Figure\n",
    "def plot_AE_history(history):\n",
    "    plt.plot(history.history['loss'],\n",
    "             'b',\n",
    "             label='Training loss')\n",
    "    plt.plot(history.history['val_loss'],\n",
    "             'r',\n",
    "             label='Validation loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss, [mse]')\n",
    "    plt.ylim([0, .1])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "history = AutoEncoder_main(model=model, Epochs=40, BATCH_SIZE=10, validation_split=0.05)\n",
    "\n",
    "#plot_AE_history(history)\n",
    "\n",
    "\n",
    "\n",
    "### 五、指标检测 ###\n",
    "# 查看模型认知水平\n",
    "X_pred = model.predict(np.array(X_train))\n",
    "X_pred = pd.DataFrame(X_pred,\n",
    "                      columns=X_train.columns)\n",
    "X_pred.index = X_train.index\n",
    "\n",
    "scored = pd.DataFrame(index=X_train.index)\n",
    "scored['Loss_mae'] = np.mean(np.abs(X_pred-X_train), axis = 1)\n",
    "plt.figure()\n",
    "sns.distplot(scored['Loss_mae'],\n",
    "             bins = 10,\n",
    "             kde= True,\n",
    "            color = 'blue')\n",
    "plt.xlim([0.0,.5])\n",
    "plt.show()\n",
    "\n",
    "# 对测试集进行异常诊断\n",
    "X_pred = model.predict(np.array(X_test))\n",
    "X_pred = pd.DataFrame(X_pred,\n",
    "                      columns=X_test.columns)\n",
    "\n",
    "X_pred.index = X_test.index\n",
    "\n",
    "threshod = 0.15\n",
    "scored = pd.DataFrame(index=X_test.index)\n",
    "scored['Loss_mae'] = np.mean(np.abs(X_pred-X_test), axis = 1)\n",
    "scored['Threshold'] = threshod\n",
    "scored['Anomaly'] = scored['Loss_mae'] > scored['Threshold']\n",
    "scored.head()\n",
    "\n",
    "X_pred_train = model.predict(np.array(X_train))\n",
    "X_pred_train = pd.DataFrame(X_pred_train,\n",
    "                      columns=X_train.columns)\n",
    "X_pred_train.index = X_train.index\n",
    "\n",
    "scored_train = pd.DataFrame(index=X_train.index)\n",
    "scored_train['Loss_mae'] = np.mean(np.abs(X_pred_train-X_train), axis = 1)\n",
    "scored_train['Threshold'] = threshod\n",
    "scored_train['Anomaly'] = scored_train['Loss_mae'] > scored_train['Threshold']\n",
    "scored = pd.concat([scored_train, scored])\n",
    "\n",
    "scored.plot(logy=True,  figsize = (10,6),xlim = ['2021-12-01','2021-12-31'],ylim = [1e-2,1e1], color = ['blue','red'])\n",
    "\n",
    "plt.vlines(['2021-12-15 15:00:00'],ymin=1e-2,ymax=1e1,label='vlines',color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21635968",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
