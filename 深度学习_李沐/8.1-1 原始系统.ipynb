{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c44c0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "login success!\n",
      "login respond error_code:0\n",
      "login respond  error_msg:success\n",
      "query_history_k_data_plus respond error_code:0\n",
      "query_history_k_data_plus respond  error_msg:success\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 7)) while a minimum of 1 is required by MinMaxScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 53>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m### 二、数据预处理 ###\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# 归一化\u001b[39;00m\n\u001b[0;32m     52\u001b[0m scaler \u001b[38;5;241m=\u001b[39m preprocessing\u001b[38;5;241m.\u001b[39mMinMaxScaler()\n\u001b[1;32m---> 53\u001b[0m X_result \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m,columns\u001b[38;5;241m=\u001b[39mresult\u001b[38;5;241m.\u001b[39mcolumns,index\u001b[38;5;241m=\u001b[39mresult\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m### 三、导入模型 ###\u001b[39;00m\n\u001b[0;32m     56\u001b[0m model\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/23665/model_1htdq.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 142\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    147\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    148\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:859\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    858\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\preprocessing\\_data.py:427\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\preprocessing\\_data.py:466\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    461\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMinMaxScaler does not support sparse input. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider using MaxAbsScaler instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    463\u001b[0m     )\n\u001b[0;32m    465\u001b[0m first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 466\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_pass\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m data_min \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmin(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    474\u001b[0m data_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmax(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:546\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 546\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    547\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:931\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[1;32m--> 931\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    932\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    933\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    934\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m    935\u001b[0m         )\n\u001b[0;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    938\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 7)) while a minimum of 1 is required by MinMaxScaler."
     ]
    }
   ],
   "source": [
    "# %load  8.1-1 原始save-系统.py\n",
    "import baostock as bs\n",
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### 一、获取数据并修改类型 ###\n",
    "## 登陆系统\n",
    "lg = bs.login()\n",
    "# 显示登陆返回信息\n",
    "print('login respond error_code:'+lg.error_code)\n",
    "print('login respond  error_msg:'+lg.error_msg)\n",
    "\n",
    "## 获取沪深A股历史K线数据\n",
    "# 详细指标参数，参见“历史行情指标参数”章节；“分钟线”参数与“日线”参数不同。“分钟线”不包含指数。\n",
    "# 分钟线指标：date,time,code,open,high,low,close,volume,amount,adjustflag\n",
    "rs = bs.query_history_k_data_plus(\"sz.002025\",\n",
    "    \"date,time,code,open,high,low,close,volume,amount,adjustflag\",\n",
    "    start_date=(datetime.date.today() + datetime.timedelta(days=-1)).strftime('%Y-%m-%d'),\n",
    "    end_date=datetime.date.today().strftime('%Y-%m-%d'),\n",
    "    frequency=\"5\", adjustflag=\"3\")\n",
    "print('query_history_k_data_plus respond error_code:'+rs.error_code)\n",
    "print('query_history_k_data_plus respond  error_msg:'+rs.error_msg)\n",
    "\n",
    "## 打印结果集\n",
    "data_list = []\n",
    "while (rs.error_code == '0') & rs.next():\n",
    "    # 获取一条记录，将记录合并在一起\n",
    "    data_list.append(rs.get_row_data())\n",
    "result = pd.DataFrame(data_list, columns=rs.fields)\n",
    "\n",
    "## 修改result数据类型  \n",
    "result = result.apply(pd.to_numeric,errors = 'ignore')  # 将dataframe中元素变为数值类型\n",
    "result = result.drop(['date','code'],axis = 1)   # 删掉指定列，'date'和'code'为列名\n",
    "result = result.set_index('time')                # 设置'time'列为指定行名\n",
    "result.index = pd.to_datetime(result.index, format ='%Y%m%d%H%M%S%f')\n",
    "\n",
    "\n",
    "### 二、数据预处理 ###\n",
    "# 归一化\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_result = pd.DataFrame(scaler.fit_transform(result),columns=result.columns,index=result.index)\n",
    "\n",
    "### 三、导入模型 ###\n",
    "model=keras.models.load_model('C:/Users/23665/model_1htdq.h5')\n",
    "\n",
    "\n",
    "### 四、查看模型的“认知水平” ###\n",
    "X_pred = model.predict(np.array(X_result))\n",
    "X_pred = pd.DataFrame(X_pred,\n",
    "                      columns=X_result.columns)\n",
    "X_pred.index = X_result.index\n",
    "\n",
    "scored = pd.DataFrame(index=X_result.index)\n",
    "scored['Loss_mae'] = np.mean(np.abs(X_pred-X_result), axis = 1)\n",
    "plt.figure()\n",
    "sns.distplot(scored['Loss_mae'],\n",
    "              bins = 10,\n",
    "              kde= True,\n",
    "            color = 'blue')\n",
    "plt.xlim([0.0,.5])\n",
    "\n",
    "\n",
    "### 五、对测试集进行异常诊断 ###\n",
    "X_pred = model.predict(np.array(X_result))\n",
    "X_pred = pd.DataFrame(X_pred,\n",
    "                      columns=X_result.columns)\n",
    "X_pred.index = X_result.index\n",
    "\n",
    "\n",
    "threshod = 0.36\n",
    "scored = pd.DataFrame(index=X_result.index)\n",
    "scored['Loss_mae'] = np.mean(np.abs(X_pred-X_result), axis = 1)\n",
    "scored['Threshold'] = threshod\n",
    "scored['Anomaly'] = scored['Loss_mae'] > scored['Threshold']\n",
    "scored.head()\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "scored.plot(logy=True,  figsize = (10,6),xlim = [(datetime.strptime(scored.index[0],'%Y/%m/%d').date()),\n",
    "                                               (datetime.strptime(scored.index[-1],'%Y/%m/%d').date()),ylim = [1e-2,1e1], color = ['blue','red'])\n",
    "'''\n",
    "#datetime.strptime('2018/3/15', '%Y/%m/%d').date()\n",
    "#为什么开始时间和最后时间一样？tmd\n",
    "print(scored.index[0])\n",
    "print(scored.index[-1])\n",
    "from datetime import datetime\n",
    "\n",
    "print(datetime.strptime(str(scored.index[0]), '%Y-%m-%d %H:%M:%S').date())\n",
    "\n",
    "scored.plot(logy=True,  figsize = (10,6),xlim = [datetime.strptime(str(scored.index[0]), '%Y-%m-%d %H:%M:%S'),\n",
    "                                               datetime.strptime(str(scored.index[-1]), '%Y-%m-%d %H:%M:%S')],ylim = [1e-2,1e1], color = ['blue','red'])\n",
    "\n",
    "scored.plot(logy=True,  figsize = (10,6),xlim = [datetime.strptime(str(scored.index[0]), '%Y-%m-%d %H:%M:%S').date(),\n",
    "                                               datetime.strptime(str(scored.index[-1]), '%Y-%m-%d %H:%M:%S')].date(),ylim = [1e-2,1e1], color = ['blue','red'])\n",
    "\n",
    "'''\n",
    "scored.plot(logy=True,  figsize = (10,6),xlim = [(scored.index[0]).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                                               (scored.index[-1]).strftime('%Y-%m-%d %H:%M:%S')],ylim = [1e-2,1e1], color = ['blue','red'])\n",
    "'''\n",
    "\n",
    "Anomaly=scored[\"Anomaly\"].sum()\n",
    "\n",
    "print('异常点个数为：%d'%Anomaly)\n",
    "if 0 <= Anomaly <= 10:\n",
    "    print('风险等级：无风险')\n",
    "elif 10 < Anomaly <= 20:\n",
    "    print('风险等级：黄色预警')\n",
    "elif 20 < Anomaly <= 30:\n",
    "    print('风险等级：橙色预警')\n",
    "else:\n",
    "    print('风险等级：红色预警')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24ed836b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "异常点个数为：0\n",
      "风险等级：无风险\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "Anomaly=scored[\"Anomaly\"].sum()\n",
    "\n",
    "print('异常点个数为：%d'%Anomaly)\n",
    "if 0 <= Anomaly <= 10:\n",
    "    print('风险等级：无风险')\n",
    "elif 10 < Anomaly <= 20:\n",
    "    print('风险等级：黄色预警')\n",
    "elif 20 < Anomaly <= 30:\n",
    "    print('风险等级：橙色预警')\n",
    "else:\n",
    "    print('风险等级：红色预警')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcfa899",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
