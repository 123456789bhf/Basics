{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a19ac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Legacy code ===============\n",
    "\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "\n",
    "def tf_namespace(namespace):\n",
    "    def wrapper(f):\n",
    "        def wrapped_f(*args, **kwargs):\n",
    "            with tf.name_scope(namespace):\n",
    "                return f(*args, **kwargs)\n",
    "\n",
    "        return wrapped_f\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "class VAE:\n",
    "\n",
    "    def __init__(self, input_shape, encode_sizes, latent_size, decode_sizes=None, mu_prior=None, sigma_prior=None,\n",
    "                 lr=10e-4,  momentum=0.9, save_model=True):\n",
    "        self.encode_sizes = encode_sizes\n",
    "        self.latent_size = latent_size\n",
    "        self.decode_sizes = decode_sizes or encode_sizes[::-1]\n",
    "        self.mu_prior = mu_prior or np.zeros([latent_size], dtype='float32')\n",
    "        self.sigma_prior = sigma_prior or np.ones([latent_size], 'float32')\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.input_shape = input_shape\n",
    "        self.save_model = save_model\n",
    "        self._build_graph(input_shape, latent_size)\n",
    "\n",
    "    def _build_graph(self, input_shape, latent_size):\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            self._create_placeholders(input_shape)\n",
    "            self._create_encoder(self.X)\n",
    "            self._create_latent_distribution(self.encoder, latent_size)\n",
    "            self._create_decoder(self.z)\n",
    "            self.loss = - self.elbo(self.X, self.decoder, self.mu, self.log_sigma_square, self.sigma_square,\n",
    "                                    tf.constant(self.mu_prior), tf.constant(self.sigma_prior))\n",
    "            self.opt = tf.train.AdamOptimizer(self.lr, self.momentum)\n",
    "            self.opt_op = self.opt.minimize(self.loss)\n",
    "            self.session = tf.InteractiveSession(graph=self.graph)\n",
    "        writer = tf.summary.FileWriter(logdir='logdir', graph=self.graph)\n",
    "        writer.flush()\n",
    "\n",
    "    @property\n",
    "    def k_init(self):\n",
    "        return {'kernel_initializer': tf.glorot_uniform_initializer()}\n",
    "\n",
    "    def elbo(self, X_true, X_pred, mu, log_sigma, sigma, mu_prior, sigma_prior):\n",
    "        epsilon = tf.constant(0.000001)\n",
    "        self.mae = tf.losses.absolute_difference(X_true, X_pred, reduction=tf.losses.Reduction.NONE)\n",
    "        self.mae_sum = tf.reduce_sum(self.mae, axis=1)\n",
    "        log_sigma_prior = tf.log(sigma_prior + epsilon)\n",
    "        mu_diff = mu - mu_prior\n",
    "        self.kl = log_sigma_prior - log_sigma - 1 + (sigma + tf.multiply(mu_diff, mu_diff)) / sigma_prior\n",
    "        self.kl_sum = tf.reduce_sum(self.kl, axis=1)\n",
    "        return tf.reduce_mean(- self.mae_sum - self.kl_sum)\n",
    "\n",
    "    @tf_namespace('placeholders')\n",
    "    def _create_placeholders(self, input_shape):\n",
    "        self.X = tf.placeholder(tf.float32, shape=[None, *input_shape], name='X')\n",
    "\n",
    "    @tf_namespace('encoder')\n",
    "    def _create_encoder(self, X):\n",
    "        self.encode_layers = []\n",
    "        self.encoder = X\n",
    "        for i, lsize in enumerate(self.encode_sizes):\n",
    "            self.encoder = tf.layers.dense(self.encoder, lsize, **self.k_init,\n",
    "                                           activation=tf.nn.relu, name=f'encoder_{i + 1}')\n",
    "            self.encode_layers.append(self.encoder)\n",
    "            setattr(self, f'encoder_{i + 1}', self.encoder)\n",
    "\n",
    "    @tf_namespace('latent')\n",
    "    def _create_latent_distribution(self, encoder, latent_dim):\n",
    "        self.mu = tf.layers.dense(encoder, latent_dim, **self.k_init, name='mu')\n",
    "        self.log_sigma_square = tf.layers.dense(encoder, latent_dim,\n",
    "                                                **self.k_init, name='log_sigma_square')\n",
    "        self.sigma_square = tf.exp(self.log_sigma_square, 'sigma_square')\n",
    "        self.z = tf.add(self.mu, self.sigma_square * tf.random.normal(tf.shape(self.sigma_square)), 'z')\n",
    "\n",
    "    @tf_namespace('decoder')\n",
    "    def _create_decoder(self, z):\n",
    "        self.decoder = z\n",
    "        self.decode_layers = []\n",
    "        for i, lsize in enumerate(self.decode_sizes):\n",
    "            self.decoder = tf.layers.dense(self.decoder, lsize, **self.k_init,\n",
    "                                           activation=tf.nn.relu, name=f'decoder_{i + 1}')\n",
    "            setattr(self, f'decoder_{i + 1}', self.decoder)\n",
    "            self.decode_layers.append(self.decoder)\n",
    "            if i == len(self.decode_sizes) - 1:\n",
    "                self.mu_post = tf.layers.dense(self.decoder, self.input_shape[0], name='mu_posterior')\n",
    "                self.log_sigma_post = tf.layers.dense(self.decoder, self.input_shape[0])\n",
    "                self.sigma_post = tf.exp(self.log_sigma_post, 'sigma_square_posterior')\n",
    "                self.decoder = tf.add(self.mu_post,\n",
    "                                      self.sigma_post * tf.random.normal((self.input_shape[0],), name='eps_post'),\n",
    "                                      name='decoder_output')\n",
    "                setattr(self, f'decoder_{i + 2}', self.decoder)\n",
    "                self.decode_layers.append(self.decoder)\n",
    "        return self.decoder\n",
    "\n",
    "    @property\n",
    "    def layers(self):\n",
    "        return [(f'encoder_{i}', getattr(self, f'encoder_{i}')) for i in range(1, len(self.encode_layers) + 1)] + \\\n",
    "               [('mu', self.mu), ('sigma', self.log_sigma_square), ('z', self.z)] + \\\n",
    "               [(f'decoder_{i}', getattr(self, f'decoder_{i}')) for i in range(1, len(self.decode_layers) + 1)]\n",
    "\n",
    "    def fit(self, X, epochs, batch_size, print_every=50, save_every_epochs=5, verbose=True):\n",
    "        n_batch = ceil(X.shape[0] / batch_size)\n",
    "        if self.save_model:\n",
    "            saver = tf.train.Saver()\n",
    "        self.session.run(tf.global_variables_initializer())\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            np.random.shuffle(X)\n",
    "            acc_loss = 0\n",
    "            counter = 0\n",
    "            for i in range(n_batch):\n",
    "                slice_batch = slice(i * batch_size, (i + 1) * batch_size) if i != n_batch - 1 else slice(\n",
    "                    i * batch_size,\n",
    "                    None)\n",
    "                X_batch = X[slice_batch, :]\n",
    "                batch_loss, _ = self.session.run([self.loss, self.opt_op], {self.X: X_batch})\n",
    "                acc_loss += batch_loss\n",
    "                if verbose and counter % print_every == 0:\n",
    "                    print(f\" Epoch {epoch} - batch {i} - neg_ELBO = {batch_loss}\")\n",
    "                counter += 1\n",
    "            if verbose:\n",
    "                print(f'\\nEpoch {epoch} - Avg loss = {acc_loss / n_batch}')\n",
    "                print('\\n' + ('-' * 70))\n",
    "            if self.save_model and (epoch+1) % save_every_epochs == 0:\n",
    "                saver.save(self.session, \"ckpts/ad_vae.ckpt\")\n",
    "\n",
    "    def generate(self, n=1, mu_prior=None, sigma_prior=None):\n",
    "        \"\"\"\n",
    "        Generate new examples sampling from the latent distribution\n",
    "        :param n: number of examples to generate\n",
    "        :param mu_prior:\n",
    "        :param sigma_prior:\n",
    "        :return: a matrix of size [n, p] where p is the number of variables of X_train\n",
    "        \"\"\"\n",
    "        if mu_prior is None:\n",
    "            mu_prior = self.mu_prior\n",
    "        if sigma_prior is None:\n",
    "            sigma_prior = self.sigma_prior\n",
    "        z = np.random.multivariate_normal(mu_prior, np.diag(sigma_prior), [n])\n",
    "        return self.session.run(self.decoder, feed_dict={self.z: z})\n",
    "\n",
    "    def reconstruct(self, X):\n",
    "        return self.session.run(self.decoder, feed_dict={self.X: X})\n",
    "\n",
    "    def reconstructed_probability(self, X, L=100):\n",
    "        reconstructed_prob = np.zeros((X.shape[0],), dtype='float32')\n",
    "        mu_hat, sigma_hat = self.session.run([self.mu_post, self.sigma_post], {self.X: X})\n",
    "        for l in range(L):\n",
    "            mu_hat = mu_hat.reshape(X.shape)\n",
    "            sigma_hat = sigma_hat.reshape(X.shape) + 0.00001\n",
    "            for i in range(X.shape[0]):\n",
    "                p_l = multivariate_normal.pdf(X[i, :], mu_hat[i, :], np.diag(sigma_hat[i, :]))\n",
    "                reconstructed_prob[i] += p_l\n",
    "        reconstructed_prob /= L\n",
    "        return reconstructed_prob\n",
    "\n",
    "    def is_outlier(self, X, L=100, alpha=0.05):\n",
    "        p_hat = self.reconstructed_probability(X, L)\n",
    "        return p_hat < alpha\n",
    "\n",
    "    def open(self):\n",
    "        if not hasattr(self, 'session') or self.session is None:\n",
    "            if self.graph is None:\n",
    "                self._build_graph(self.input_shape, self.latent_size)\n",
    "            else:\n",
    "                self.session = tf.InteractiveSession(graph=self.graph)\n",
    "\n",
    "    def close(self):\n",
    "        if hasattr(VAE, 'session') and VAE.session is not None:\n",
    "            VAE.session.close()\n",
    "            VAE.session = None\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.close()\n",
    "\n",
    "    def __delete__(self, instance):\n",
    "        self.close()\n",
    "\n",
    "    def __setattr__(self, key, value):\n",
    "        if key == 'session':\n",
    "            if hasattr(self, 'session') and self.session is not None:\n",
    "                self.close()\n",
    "            VAE.session = value\n",
    "        else:\n",
    "            self.__dict__[key] = value\n",
    "\n",
    "    def __delattr__(self, item):\n",
    "        if item == 'session':\n",
    "            self.close()\n",
    "            del VAE.__dict__['session']\n",
    "        else:\n",
    "            del self.__dict__[item]\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.open()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9024ee37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
